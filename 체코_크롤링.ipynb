{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoiGhjuZzD9m",
    "outputId": "a7128646-16ed-4c56-f6ad-5a3e6eb0221d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'apt'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hansh\\anaconda3\\lib\\site-packages (4.28.1)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\hansh\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hansh\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!apt update -y\n",
    "!apt install -y chromium-chromedriver\n",
    "!pip install selenium webdriver-manager beautifulsoup4\n",
    "#test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WEiivfB48Lm",
    "outputId": "42e96234-2477-4cc2-eb81-7c5e15d4efaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'apt-get'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'apt-get'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'rm'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "!apt-get remove -y chromium-browser\n",
    "!apt-get purge -y chromium-chromedriver\n",
    "!apt-get autoremove -y\n",
    "!rm -rf /usr/bin/chromedriver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQKH4J9l49--",
    "outputId": "caeca7fc-aad2-4b01-c80e-6d85ac83b13c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'apt'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'wget'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'dpkg'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'apt'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install -y wget unzip\n",
    "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
    "!dpkg -i google-chrome-stable_current_amd64.deb\n",
    "!apt --fix-broken install -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08LFozSZ5CtV",
    "outputId": "9cf17a2d-4317-4728-970e-a995b97d7a61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'google-chrome'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "!google-chrome --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TseL_vzi5spH",
    "outputId": "1e6c3a65-414e-48bb-9448-bd3be52be215"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'unzip'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'mv'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
      "'chmod'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "CHROME_VERSION = \"133\"  # ìœ„ì—ì„œ í™•ì¸í•œ Chrome ë²„ì „ ì• 3ìë¦¬ ì…ë ¥ (ì˜ˆ: 120)\n",
    "\n",
    "!wget https://chromedriver.storage.googleapis.com/{CHROME_VERSION}.0.6099.71/chromedriver_linux64.zip\n",
    "!unzip chromedriver_linux64.zip\n",
    "!mv chromedriver /usr/bin/chromedriver\n",
    "!chmod +x /usr/bin/chromedriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEiScjbn6aUY",
    "outputId": "f9228252-8434-4026-ffd4-76cd18378e21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'google-chrome'ì€(ëŠ”) ë‚´ë¶€ ë˜ëŠ” ì™¸ë¶€ ëª…ë ¹, ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨, ë˜ëŠ”\n",
      "ë°°ì¹˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] ì§€ì •ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m chrome_version \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle-chrome\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--version\u001b[39m\u001b[38;5;124m\"\u001b[39m], capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m      9\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\"\u001b[39m, chrome_version)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] ì§€ì •ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
     ]
    }
   ],
   "source": [
    "# ìµœì‹  Chrome ë²„ì „ í™•ì¸\n",
    "!google-chrome --version\n",
    "\n",
    "# Chrome ë²„ì „ ìë™ ì¶”ì¶œ\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "chrome_version = subprocess.run([\"google-chrome\", \"--version\"], capture_output=True, text=True).stdout\n",
    "match = re.search(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", chrome_version)\n",
    "if match:\n",
    "    CHROME_VERSION = match.group(0)\n",
    "else:\n",
    "    raise Exception(\"Chrome ë²„ì „ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"âœ… Chrome Version Detected: {CHROME_VERSION}\")\n",
    "\n",
    "# Chrome ë²„ì „ì— ë§ëŠ” Chromedriver ë‹¤ìš´ë¡œë“œ\n",
    "CHROMEDRIVER_URL = f\"https://storage.googleapis.com/chrome-for-testing-public/{CHROME_VERSION}/linux64/chromedriver-linux64.zip\"\n",
    "\n",
    "!wget -O chromedriver.zip {CHROMEDRIVER_URL}\n",
    "!unzip chromedriver.zip\n",
    "!mv chromedriver-linux64/chromedriver /usr/bin/chromedriver\n",
    "!chmod +x /usr/bin/chromedriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chrome WebDriverê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Chrome WebDriver ìë™ ì„¤ì¹˜\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "print(\"âœ… Chrome WebDriverê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mh1V8EEX6kjg",
    "outputId": "b88b7a01-9399-4a2e-fdc6-48652a164846"
   },
   "outputs": [],
   "source": [
    "!which chromedriver\n",
    "!chromedriver --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JadernÃ¡ elektrÃ¡rna Dukovany(ë‘ì½”ë°”ë‹ˆ ì›ìë ¥ ë°œì „ì†Œ)\n",
    "\n",
    "#https://search.seznam.cz/clanky/?q=Jadern%C3%A1%20elektr%C3%A1rna%20Dukovany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ” ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸\n",
    "search_queries = [\"ë‘ì½”ë°”ë‹ˆ ì›ì „\"]  # ì›í•˜ëŠ” ê²€ìƒ‰ì–´ ì…ë ¥\n",
    "\n",
    "# âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ URL í…œí”Œë¦¿\n",
    "NAVER_NEWS_URL_TEMPLATE = \"https://search.naver.com/search.naver?where=news&query={query}&sm=tab_opt&sort=0&photo=0&field=0&pd=3&ds=2022.01.01&de=2024.12.31\"\n",
    "\n",
    "# âœ… í¬ë¡¤ë§í•  ë‚ ì§œ ë²”ìœ„\n",
    "START_DATE = datetime.datetime(2024, 9, 5)\n",
    "END_DATE = datetime.datetime(2024, 12, 31)\n",
    "\n",
    "# âœ… User-Agent ì„¤ì •\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# âœ… Selenium ì˜µì…˜ ì„¤ì • (Chrome Headless ëª¨ë“œ)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # GUI ì—†ì´ ì‹¤í–‰\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "# âœ… ChromeDriver ìë™ ì„¤ì¹˜\n",
    "service = Service(ChromeDriverManager().install())  # Chromedriver ìë™ ë‹¤ìš´ë¡œë“œ ë° ê²½ë¡œ ì„¤ì •\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "def fetch_naver_news(query):\n",
    "    \"\"\"Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ í˜ì´ì§€ í¬ë¡¤ë§ (ë¬´í•œ ìŠ¤í¬ë¡¤)\"\"\"\n",
    "    search_url = NAVER_NEWS_URL_TEMPLATE.format(query=query)\n",
    "    driver.get(search_url)\n",
    "    time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "\n",
    "    # âœ… ë¬´í•œ ìŠ¤í¬ë¡¤ì„ í†µí•´ ë‰´ìŠ¤ ëª©ë¡ ë¡œë“œ\n",
    "    print(f\"ğŸ” ê²€ìƒ‰ ì¤‘: {query} (ìŠ¤í¬ë¡¤ í¬ë¡¤ë§ ì‹œì‘)\")\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.END)\n",
    "        time.sleep(2)  # ë¡œë”© ëŒ€ê¸°\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break  # ë” ì´ìƒ ë¡œë”©í•  ë‚´ìš© ì—†ìŒ\n",
    "        last_height = new_height\n",
    "\n",
    "    # âœ… BeautifulSoupìœ¼ë¡œ í˜ì´ì§€ íŒŒì‹±\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    articles = soup.select(\"div.group_news > ul.list_news > li\")\n",
    "\n",
    "    news_list = []\n",
    "    for article in articles:\n",
    "        try:\n",
    "            title_element = article.select_one(\"a.news_tit\")\n",
    "            title = title_element.text.strip() if title_element else \"N/A\"\n",
    "            link = title_element[\"href\"] if title_element else \"N/A\"\n",
    "\n",
    "            # âœ… ë‚ ì§œ ê°€ì ¸ì˜¤ê¸° (ëª©ë¡ì—ì„œ ì§ì ‘ í¬ë¡¤ë§)\n",
    "            date_element = article.select_one(\"span.info\")\n",
    "            date_text = date_element.text.strip() if date_element else \"N/A\"\n",
    "\n",
    "            news_list.append({\"title\": title, \"link\": link, \"date\": date_text})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš  ì˜¤ë¥˜ ë°œìƒ (ëª©ë¡ í¬ë¡¤ë§ ì‹¤íŒ¨): {e}\")\n",
    "\n",
    "    print(f\"âœ… {len(news_list)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ë§í¬ ë° ë‚ ì§œë¥¼ ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "    return news_list\n",
    "\n",
    "def fetch_news_content(news_list):\n",
    "    \"\"\"ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§\"\"\"\n",
    "    news_data = []\n",
    "\n",
    "    for news in tqdm(news_list, desc=\"ğŸ“° ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ ì§„í–‰\"):\n",
    "        try:\n",
    "            response = requests.get(news[\"link\"], headers=HEADERS)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # âœ… ë³¸ë¬¸ í¬ë¡¤ë§ (ë‹¤ì–‘í•œ ì„ íƒì ì¶”ê°€)\n",
    "            content_selectors = [\n",
    "                \"div#newsct_article\",  # ìµœì‹  ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸\n",
    "                \"div#articleBodyContents\",  # ê³¼ê±° ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸\n",
    "                \"div.article_view\",\n",
    "                \"div.news_end\",\n",
    "                \"div#articeBody\",\n",
    "                \"div.content_area\",\n",
    "                \"div#newsEndContents\",\n",
    "                \"article\"\n",
    "            ]\n",
    "            content = \"\"\n",
    "            for selector in content_selectors:\n",
    "                content_element = soup.select(selector)\n",
    "                if content_element:\n",
    "                    content = \" \".join([p.text.strip() for p in content_element])\n",
    "                    break\n",
    "\n",
    "            # âœ… Fallback: Seleniumìœ¼ë¡œ ì§ì ‘ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°\n",
    "            if not content.strip():\n",
    "                print(f\"âš  ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í•´ Seleniumìœ¼ë¡œ ì¬ì‹œë„: {news['link']}\")\n",
    "                driver.get(news[\"link\"])\n",
    "                time.sleep(2)\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                content_element = soup.select_one(\"div#newsct_article\") or soup.select_one(\"article\")\n",
    "                if content_element:\n",
    "                    content = \" \".join([p.text.strip() for p in content_element])\n",
    "\n",
    "            # âœ… ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ ë‚ ì§œ í™•ì¸ (ëª©ë¡ê³¼ ë¹„êµ)\n",
    "            meta_date_element = soup.select_one(\"meta[property='article:published_time']\")\n",
    "            if meta_date_element:\n",
    "                article_date = meta_date_element[\"content\"][:10].replace(\"-\", \".\")  # 'YYYY-MM-DD' -> 'YYYY.MM.DD'\n",
    "                news[\"date\"] = article_date  # ëª©ë¡ì—ì„œ ê°€ì ¸ì˜¨ ë‚ ì§œë¥¼ ë®ì–´ì”€\n",
    "\n",
    "            # âœ… ë°ì´í„° ì €ì¥\n",
    "            news[\"content\"] = content.strip() if content else \"N/A\"\n",
    "            news_data.append(news)\n",
    "\n",
    "            print(f\"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {news['title'][:50]}...\")\n",
    "\n",
    "            time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš  ì˜¤ë¥˜ ë°œìƒ (ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨): {news['link']}, ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    return news_data\n",
    "\n",
    "# âœ… ì „ì²´ ê²€ìƒ‰ì–´ì— ëŒ€í•´ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰\n",
    "all_news = []\n",
    "for query in search_queries:\n",
    "    news_list = fetch_naver_news(query)\n",
    "    news_data = fetch_news_content(news_list)\n",
    "    all_news.extend(news_data)\n",
    "\n",
    "# âœ… JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "output_file = \"naver_news.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_news, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"âœ… ì´ {len(all_news)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. (íŒŒì¼ëª…: {output_file})\")\n",
    "\n",
    "# âœ… Selenium ì¢…ë£Œ\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvBil8JomQZ-",
    "outputId": "2d43e6ee-8332-482f-b3df-e60c46473a89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê²€ìƒ‰ ì¤‘: ë‘ì½”ë°”ë‹ˆ ì›ì „ (ìŠ¤í¬ë¡¤ í¬ë¡¤ë§ ì‹œì‘)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ” ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸\n",
    "search_queries = [\"ë‘ì½”ë°”ë‹ˆ ì›ì „\"]  # ì›í•˜ëŠ” ê²€ìƒ‰ì–´ ì…ë ¥\n",
    "\n",
    "# âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ URL í…œí”Œë¦¿\n",
    "NAVER_NEWS_URL_TEMPLATE = \"https://search.naver.com/search.naver?where=news&query={query}&sm=tab_opt&sort=0&photo=0&field=0&pd=3&ds=2022.01.01&de=2024.12.31\"\n",
    "\n",
    "# âœ… í¬ë¡¤ë§í•  ë‚ ì§œ ë²”ìœ„\n",
    "START_DATE = datetime.datetime(2022, 1, 1)\n",
    "END_DATE = datetime.datetime(2024, 12, 31)\n",
    "\n",
    "# âœ… User-Agent ì„¤ì •\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# âœ… Selenium ì˜µì…˜ ì„¤ì • (Chrome Headless ëª¨ë“œ)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # GUI ì—†ì´ ì‹¤í–‰\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "# âœ… ChromeDriver ìë™ ì„¤ì¹˜\n",
    "service = Service(ChromeDriverManager().install())  # Chromedriver ìë™ ë‹¤ìš´ë¡œë“œ ë° ê²½ë¡œ ì„¤ì •\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "def fetch_naver_news(query):\n",
    "    \"\"\"Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ í˜ì´ì§€ í¬ë¡¤ë§ (ë¬´í•œ ìŠ¤í¬ë¡¤)\"\"\"\n",
    "    search_url = NAVER_NEWS_URL_TEMPLATE.format(query=query)\n",
    "    driver.get(search_url)\n",
    "    time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "\n",
    "    # âœ… ë¬´í•œ ìŠ¤í¬ë¡¤ì„ í†µí•´ ë‰´ìŠ¤ ëª©ë¡ ë¡œë“œ\n",
    "    print(f\"ğŸ” ê²€ìƒ‰ ì¤‘: {query} (ìŠ¤í¬ë¡¤ í¬ë¡¤ë§ ì‹œì‘)\")\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.END)\n",
    "        time.sleep(2)  # ë¡œë”© ëŒ€ê¸°\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break  # ë” ì´ìƒ ë¡œë”©í•  ë‚´ìš© ì—†ìŒ\n",
    "        last_height = new_height\n",
    "\n",
    "    # âœ… BeautifulSoupìœ¼ë¡œ í˜ì´ì§€ íŒŒì‹±\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    articles = soup.select(\"div.group_news > ul.list_news > li\")\n",
    "\n",
    "    news_list = []\n",
    "    for article in articles:\n",
    "        try:\n",
    "            title_element = article.select_one(\"a.news_tit\")\n",
    "            title = title_element.text.strip() if title_element else \"N/A\"\n",
    "            link = title_element[\"href\"] if title_element else \"N/A\"\n",
    "\n",
    "            # âœ… ë‚ ì§œ ê°€ì ¸ì˜¤ê¸° (ëª©ë¡ì—ì„œ ì§ì ‘ í¬ë¡¤ë§)\n",
    "            date_element = article.select_one(\"span.info\")\n",
    "            date_text = date_element.text.strip() if date_element else \"N/A\"\n",
    "\n",
    "            news_list.append({\"title\": title, \"link\": link, \"date\": date_text})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš  ì˜¤ë¥˜ ë°œìƒ (ëª©ë¡ í¬ë¡¤ë§ ì‹¤íŒ¨): {e}\")\n",
    "\n",
    "    print(f\"âœ… {len(news_list)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ë§í¬ ë° ë‚ ì§œë¥¼ ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "    return news_list\n",
    "\n",
    "def fetch_news_content(news_list):\n",
    "    \"\"\"ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§\"\"\"\n",
    "    news_data = []\n",
    "\n",
    "    for news in tqdm(news_list, desc=\"ğŸ“° ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ ì§„í–‰\"):\n",
    "        try:\n",
    "            response = requests.get(news[\"link\"], headers=HEADERS)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # âœ… ë³¸ë¬¸ í¬ë¡¤ë§ (ë‹¤ì–‘í•œ ì„ íƒì ì¶”ê°€)\n",
    "            content_selectors = [\n",
    "                \"div#newsct_article\",  # ìµœì‹  ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸\n",
    "                \"div#articleBodyContents\",  # ê³¼ê±° ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸\n",
    "                \"div.article_view\",\n",
    "                \"div.news_end\",\n",
    "                \"div#articeBody\",\n",
    "                \"div.content_area\",\n",
    "                \"div#newsEndContents\",\n",
    "                \"article\"\n",
    "            ]\n",
    "            content = \"\"\n",
    "            for selector in content_selectors:\n",
    "                content_element = soup.select(selector)\n",
    "                if content_element:\n",
    "                    content = \" \".join([p.text.strip() for p in content_element])\n",
    "                    break\n",
    "\n",
    "            # âœ… Fallback: Seleniumìœ¼ë¡œ ì§ì ‘ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°\n",
    "            if not content.strip():\n",
    "                print(f\"âš  ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í•´ Seleniumìœ¼ë¡œ ì¬ì‹œë„: {news['link']}\")\n",
    "                driver.get(news[\"link\"])\n",
    "                time.sleep(2)\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                content_element = soup.select_one(\"div#newsct_article\") or soup.select_one(\"article\")\n",
    "                if content_element:\n",
    "                    content = \" \".join([p.text.strip() for p in content_element])\n",
    "\n",
    "            # âœ… ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ ë‚ ì§œ í™•ì¸ (ëª©ë¡ê³¼ ë¹„êµ)\n",
    "            meta_date_element = soup.select_one(\"meta[property='article:published_time']\")\n",
    "            if meta_date_element:\n",
    "                article_date = meta_date_element[\"content\"][:10].replace(\"-\", \".\")  # 'YYYY-MM-DD' -> 'YYYY.MM.DD'\n",
    "                news[\"date\"] = article_date  # ëª©ë¡ì—ì„œ ê°€ì ¸ì˜¨ ë‚ ì§œë¥¼ ë®ì–´ì”€\n",
    "\n",
    "            # âœ… ë°ì´í„° ì €ì¥\n",
    "            news[\"content\"] = content.strip() if content else \"N/A\"\n",
    "            news_data.append(news)\n",
    "\n",
    "            print(f\"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {news['title'][:50]}...\")\n",
    "\n",
    "            time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš  ì˜¤ë¥˜ ë°œìƒ (ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨): {news['link']}, ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    return news_data\n",
    "\n",
    "# âœ… ì „ì²´ ê²€ìƒ‰ì–´ì— ëŒ€í•´ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰\n",
    "all_news = []\n",
    "for query in search_queries:\n",
    "    news_list = fetch_naver_news(query)\n",
    "    news_data = fetch_news_content(news_list)\n",
    "    all_news.extend(news_data)\n",
    "\n",
    "# âœ… JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "output_file = \"naver_news.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_news, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"âœ… ì´ {len(all_news)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. (íŒŒì¼ëª…: {output_file})\")\n",
    "\n",
    "# âœ… Selenium ì¢…ë£Œ\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
